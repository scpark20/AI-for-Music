{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4694a514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf3bea7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'root_dir': 'dataset/', 'max_note_duration': 2, 'token_length': 1024, 'dims': {'interval': 100, 'velocity': 32, 'note_on': 128, 'note_off': 128, 'pedal_on': 1, 'pedal_off': 1}, 'offsets': {'interval': 100, 'velocity': 100, 'note_on': 132, 'note_off': 260, 'pedal_on': 388, 'pedal_off': 389}}\n"
     ]
    }
   ],
   "source": [
    "from easydict import EasyDict\n",
    "dims = EasyDict(interval = 100,\n",
    "                velocity = 32,\n",
    "                note_on = 128,\n",
    "                note_off = 128,\n",
    "                pedal_on = 1,\n",
    "                pedal_off = 1)\n",
    "\n",
    "offsets = EasyDict(interval = 100,\n",
    "                   velocity = dims.interval,\n",
    "                   note_on = dims.interval + dims.velocity,\n",
    "                   note_off = dims.interval + dims.velocity + dims.note_on,\n",
    "                   pedal_on = dims.interval + dims.velocity + dims.note_on + dims.note_off,\n",
    "                   pedal_off = dims.interval + dims.velocity + dims.note_on + dims.note_off + dims.pedal_on)\n",
    "\n",
    "dataset_hparams = EasyDict(root_dir = 'dataset/',\n",
    "                           max_note_duration = 2, # seconds)\n",
    "                           token_length = 1024,\n",
    "                           dims = dims,\n",
    "                           offsets = offsets\n",
    "                          )\n",
    "print(dataset_hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb703e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_list_to_tokens(event_list, hp):\n",
    "    tokens = []\n",
    "    current_time = 0\n",
    "    for event in event_list:\n",
    "        interval = event['time'] - current_time\n",
    "        interval_token = int(interval / hp.max_note_duration * hp.dims.interval)\n",
    "        interval_token = min(interval_token, hp.dims.interval)\n",
    "        tokens.append(interval_token)\n",
    "        current_time = event['time']\n",
    "        \n",
    "        if event['type'] == 'note_on':\n",
    "            tokens.append(hp.offsets.velocity + int(event['velocity'] / 128 * hp.dims.velocity))\n",
    "            tokens.append(hp.offsets.note_on + event['note'])\n",
    "        elif event['type'] == 'note_off':\n",
    "            tokens.append(hp.offsets.note_off + event['note'])\n",
    "        elif event['type'] == 'pedal_on':\n",
    "            tokens.append(hp.offsets.pedal_on)\n",
    "        elif event['type'] == 'pedal_off':\n",
    "            tokens.append(hp.offsets.pedal_off)\n",
    "    return np.array(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "537afea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaestroDataset(Dataset):\n",
    "    def __init__(self, dataset_hparams):\n",
    "        super().__init__()\n",
    "        self.hp = dataset_hparams\n",
    "        self.files = [os.path.join(self.hp.root_dir, file) for file in os.listdir(self.hp.root_dir) if 'npy' in file]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file = self.files[index]\n",
    "        event_list = np.load(file, allow_pickle=True)\n",
    "        tokens = event_list_to_tokens(event_list, self.hp)\n",
    "        if len(tokens) < self.hp.token_length:\n",
    "            start_index = 0\n",
    "        else:\n",
    "            start_index = np.random.randint(0, len(tokens)-self.hp.token_length)\n",
    "        tokens = np.array(tokens[start_index:start_index+self.hp.token_length])\n",
    "        tokens_padded = np.zeros(self.hp.token_length, dtype=np.int)\n",
    "        tokens_padded[:len(tokens)] = tokens\n",
    "        return np.array(tokens_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25827fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MaestroDataset object at 0x7f775f219130>\n"
     ]
    }
   ],
   "source": [
    "dataset = MaestroDataset(dataset_hparams)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f34cd3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f775f219490>\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset, batch_size=16)\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19b96729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1024])\n",
      "tensor([[  2, 111, 192,  ..., 116, 206,   3],\n",
      "        [348,   0, 116,  ..., 122, 196,   0],\n",
      "        [  4, 322,  13,  ...,  10, 111, 175],\n",
      "        ...,\n",
      "        [109, 194,   0,  ..., 210,   3, 338],\n",
      "        [118, 210,   0,  ..., 346,   0, 115],\n",
      "        [  4, 324,   1,  ...,   2, 113, 189]])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch.shape)\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f62106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63a44e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3cf123",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
